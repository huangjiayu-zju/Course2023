{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b89d820",
   "metadata": {},
   "source": [
    "# 2.5 Generalization in Classification\n",
    "\n",
    "It turns out that we often can guarantee generalization *a priori*:\n",
    "for many models,\n",
    "and for any desired upper bound\n",
    "on the generalization gap $\\epsilon$,\n",
    "we can often determine some required number of samples $n$\n",
    "such that if our training set contains at least $n$\n",
    "samples, our empirical error will lie\n",
    "within $\\epsilon$ of the true error,\n",
    "*for any data generating distribution*. \n",
    "\n",
    "In short, these guarantees suggest\n",
    "that ensuring generalization\n",
    "of deep neural networks *a priori*\n",
    "requires an absurd number of examples\n",
    "(perhaps trillions or more),\n",
    "even when we find that, on the tasks we care about,\n",
    "deep neural networks typically generalize\n",
    "remarkably well with far fewer examples (thousands).\n",
    "Thus deep learning practitioners often forgo\n",
    "*a priori* guarantees altogether,\n",
    "instead employing methods\n",
    "that have generalized well\n",
    "on similar problems in the past,\n",
    "and certifying generalization *post hoc*\n",
    "through empirical evaluations.\n",
    "\n",
    "## 2.5.1 The Test Set\n",
    "\n",
    "\n",
    "Let's focus on a fixed classifier $f$, suppose that we possess\n",
    "a *fresh* dataset of examples $\\mathcal{D} = {(\\mathbf{x}^{(i)},y^{(i)})}_{i=1}^n$\n",
    "that were not used to train the classifier $f$.\n",
    "The *empirical error* of our classifier $f$ on $\\mathcal{D}$\n",
    "is simply the fraction of instances\n",
    "for which the prediction $f(\\mathbf{x}^{(i)})$\n",
    "disagrees with the true label $y^{(i)}$,\n",
    "and is given by the following expression:\n",
    "\n",
    "$$\\epsilon_\\mathcal{D}(f) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}(f(\\mathbf{x}^{(i)}) \\neq y^{(i)}).$$\n",
    "\n",
    "By contrast, the *population error*\n",
    "is the *expected* fraction\n",
    "of examples in the underlying population\n",
    "(some distribution $P(X,Y)$  characterized\n",
    "by probability density function $p(\\mathbf{x},y)$)\n",
    "for which our classifier disagrees\n",
    "with the true label:\n",
    "\n",
    "$$\\epsilon(f) =  E_{(\\mathbf{x}, y) \\sim P} \\mathbf{1}(f(\\mathbf{x}) \\neq y) =\n",
    "\\int\\int \\mathbf{1}(f(\\mathbf{x}) \\neq y) p(\\mathbf{x}, y) \\;d\\mathbf{x} dy.$$\n",
    "\n",
    "\n",
    "we can view $\\epsilon_\\mathcal{D}(f)$ as a statistical\n",
    "estimator of the population error $\\epsilon(f)$.\n",
    "Moreover, because our quantity of interest $\\epsilon(f)$\n",
    "is an expectation (of the random variable $\\mathbf{1}(f(X) \\neq Y)$)\n",
    "and the corresponding estimator $\\epsilon_\\mathcal{D}(f)$\n",
    "is the sample average,\n",
    "estimating the population error\n",
    "is simply the classic problem of mean estimation.\n",
    "\n",
    "*central limit theorem* guarantees\n",
    "that whenever we possess $n$ random samples $a_1, ..., a_n$\n",
    "drawn from any distribution with mean $\\mu$ and standard deviation $\\sigma$,\n",
    "then, as the number of samples $n$ approaches infinity,\n",
    "the sample average $\\hat{\\mu}$ approximately\n",
    "tends towards a normal distribution centered\n",
    "at the true mean and with standard deviation $\\sigma/\\sqrt{n}$.This tells us something important:\n",
    "as the number of examples grows large,\n",
    "our test error $\\epsilon_\\mathcal{D}(f)$\n",
    "should approach the true error $\\epsilon(f)$\n",
    "at a rate of $\\mathcal{O}(1/\\sqrt{n})$.\n",
    "Thus, to estimate our test error twice as precisely,\n",
    "we must collect four times as large a test set.\n",
    "To reduce our test error by a factor of one hundred,\n",
    "we must collect ten thousand times as large a test set.\n",
    "\n",
    "Recall that the random variable of interest\n",
    "$\\mathbf{1}(f(X) \\neq Y)$\n",
    "can only take values $0$ and $1$\n",
    "and thus is a Bernoulli random variable,characterized by a parameter\n",
    "indicating the true error rate $\\epsilon(f)$, $1$ means that our classifier made an error. The variance $\\sigma^2$ of a Bernoulli\n",
    "depends on its parameter (here, $\\epsilon(f)$)\n",
    "according to the expression $\\epsilon(f)(1-\\epsilon(f))$. A little investigation of this function\n",
    "reveals that our variance is highest\n",
    "when the true error rate is close to $0.5$\n",
    "and can be far lower when it is\n",
    "close to $0$ or close to $1$.\n",
    "This tells us that the asymptotic standard deviation\n",
    "of our estimate $\\epsilon_\\mathcal{D}(f)$ of the error $\\epsilon(f)$\n",
    "(over the choice of the $n$ test samples)\n",
    "cannot be any greater than $\\sqrt{0.25/n}$.\n",
    "\n",
    "This tells us that if we want our test error $\\epsilon_\\mathcal{D}(f)$\n",
    "to approximate the population error $\\epsilon(f)$\n",
    "such that one standard deviation corresponds\n",
    "to an interval of $\\pm 0.01$,\n",
    "then we should collect roughly 2500 samples.\n",
    "If we want to fit two standard deviations\n",
    "in that range and thus be 95% confident\n",
    "that $\\epsilon_\\mathcal{D}(f) \\in \\epsilon(f) \\pm 0.01$,\n",
    "then we will need 10,000 samples!\n",
    "\n",
    "This turns out to be the size of the test sets\n",
    "for many popular benchmarks in machine learning.\n",
    "You might be surprised to find out that thousands\n",
    "of applied deep learning papers get published every year\n",
    "making a big deal out of error rate improvements of $0.01$ or less.\n",
    "Of course, when the error rates are much closer to $0$,\n",
    "then an improvement of $0.01$ can indeed be a big deal.\n",
    "\n",
    "Our analysis so fat has focused on asymptotics, i.e., how the relationship between $\\epsilon_\\mathcal{D}$ and $\\epsilon$\n",
    "evolves as our sample size goes to infinity.\n",
    "Fortunately, because our random variable is bounded,\n",
    "we can obtain valid finite sample bounds\n",
    "by applying an inequality due to Hoeffding (1963):\n",
    "\n",
    "$$P(\\epsilon_\\mathcal{D}(f) - \\epsilon(f) \\geq t) < \\exp\\left( - 2n t^2 \\right).$$\n",
    "\n",
    "Solving for the smallest dataset size\n",
    "that would allow us to conclude\n",
    "with 95% confidence that the distance $t$\n",
    "between our estimate $\\epsilon_\\mathcal{D}(f)$\n",
    "and the true error rate $\\epsilon(f)$\n",
    "does not exceed $0.01$,\n",
    "you will find that roughly 15,000 examples are required\n",
    "as compared to the 10,000 examples suggested\n",
    "by the asymptotic analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea368a",
   "metadata": {},
   "source": [
    "\n",
    "## 2.5.2 Test Set Reuse\n",
    "\n",
    "*multiple hypothesis testing*: When you are evaluating multiple classifiers on the same test set, the issue of false positives must be considered. A single classifier may have a 95% confidence level, but when considering 20 classifiers, you must consider the problem of false discovery, you might have no power at all to rule out the possibility that at least one among them received a misleading score.\n",
    "\n",
    "*adaptive overfitting*: When you choose $f_2$ after evaluating a test set for $f_1$, it means that the information about the test set has been leaked to the model developer. Such a test set can no longer be regarded as a true test set in the strictest sense. \n",
    "\n",
    "In practice, take care to create real test sets,\n",
    "to consult them as infrequently as possible,\n",
    "to account for multiple hypothesis testing\n",
    "when reporting confidence intervals,\n",
    "and to dial up your vigilance more aggressively\n",
    "when the stakes are high and your dataset size is small.\n",
    "When running a series of benchmark challenges,\n",
    "it is often good practice to maintain\n",
    "several test sets so that after each round,\n",
    "the old test set can be demoted to a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77964c",
   "metadata": {},
   "source": [
    "## 2.5.3 Statistical Learning Theory\n",
    "\n",
    "*statistical learning theory*,\n",
    "the mathematical subfield of machine learning\n",
    "whose practitioners aim to elucidate the\n",
    "fundamental principles that explain\n",
    "why/when models trained on empirical data\n",
    "can/will generalize to unseen data.\n",
    "One of the primary aims\n",
    "of statistical learning researchers\n",
    "has been to bound the generalization gap,\n",
    "relating the properties of the model class\n",
    "to the number of samples in the dataset.\n",
    "\n",
    "The central question of learning\n",
    "has thus historically been framed as a trade-off\n",
    "between more flexible (higher variance) model classes\n",
    "that better fit the training data but risk overfitting,\n",
    "versus more rigid (higher bias) model classes\n",
    "that generalize well but risk underfitting.\n",
    "A central question in learning theory\n",
    "has been to develop the appropriate\n",
    "mathematical analysis to quantify\n",
    "where a model sits along this spectrum,\n",
    "and to provide the associated guarantees.\n",
    "\n",
    "Vapnik--Chervonenkis (VC) dimension,\n",
    "which measures (one notion of)\n",
    "the complexity (flexibility) of a model class.\n",
    "Moreover, one of their key results bounds\n",
    "the difference between the empirical error\n",
    "and the population error as a function\n",
    "of the VC dimension and the number of samples: 模型在总体上的真实误差$R[p, f]$与其在训练集上的经验误差$R_\\textrm{emp}[\\mathbf{X}, \\mathbf{Y}, f]$之间的差异小于$\\alpha$的概率至少为$1-\\delta$\n",
    "\n",
    "$$P\\left(R[p, f] - R_\\textrm{emp}[\\mathbf{X}, \\mathbf{Y}, f] < \\alpha\\right) \\geq 1-\\delta\n",
    "\\ \\textrm{ for }\\ \\alpha \\geq c \\sqrt{(\\textrm{VC} - \\log \\delta)/n}.$$\n",
    "\n",
    "Here $\\delta > 0$ is the probability that the bound is violated(界限被违反的概率),\n",
    "$\\alpha$ is the upper bound on the generalization gap(经验误差和总体误差之间差异的上界),\n",
    "and $n$ is the dataset size(数据集的大小).\n",
    "Lastly, $c > 0$ is a constant that depends\n",
    "only on the scale of the loss that can be incurred(一个常数，仅取决于可能发生的损失的规模).\n",
    "One use of the bound might be to plug in desired\n",
    "values of $\\delta$ and $\\alpha$\n",
    "to determine how many samples to collect.\n",
    "The VC dimension quantifies the largest\n",
    "number of data points for which we can assign\n",
    "any arbitrary (binary) labeling\n",
    "and for each find some model $f$ in the class\n",
    "that agrees with that labeling. For example, linear models on $d$-dimensional inputs\n",
    "have VC dimension $d+1$.\n",
    "It is easy to see that a line can assign\n",
    "any possible labeling to three points in two dimensions,\n",
    "but not to four(二维空间中，一条线可以为三个点分配任意的标签，但对于四个点则不能).\n",
    "Unfortunately, the theory tends to be\n",
    "overly pessimistic for more complex models\n",
    "and obtaining this guarantee typically requires\n",
    "far more examples than are actually needed\n",
    "to achieve the desired error rate.(VC维度理论对于复杂模型往往过于悲观,为了达到期望的错误率，通常需要的样本数量远远超过理论所建议的)\n",
    "Note also that fixing the model class and $\\delta$,\n",
    "our error rate again decays\n",
    "with the usual $\\mathcal{O}(1/\\sqrt{n})$ rate.\n",
    "It seems unlikely that we could do better in terms of $n$.\n",
    "However, as we vary the model class,\n",
    "VC dimension can present\n",
    "a pessimistic picture\n",
    "of the generalization gap.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
