{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c089b5",
   "metadata": {},
   "source": [
    "# 5.3 Padding and Stride\n",
    "\n",
    "## 5.3.1 Padding\n",
    "\n",
    "One tricky issue when applying convolutional layers\n",
    "is that we tend to lose pixels on the perimeter of our image. Consider the folling picture that depicts the pixel utilization as a function of the convolution kernel size and the position within the image. The pixels in the corners are hardly used at all. \n",
    "\n",
    "![Pixel utilization for convolutions of size $1 \\times 1$, $2 \\times 2$, and $3 \\times 3$ respectively.](./img/conv-reuse.svg)\n",
    "\n",
    "One straightforward solution to this problem\n",
    "is to add extra pixels of filler around the boundary of our input image,\n",
    "thus increasing the effective size of the image.\n",
    "Typically, we set the values of the extra pixels to zero.\n",
    "\n",
    "In general, if we add a total of $p_\\textrm{h}$ rows of padding\n",
    "(roughly half on top and half on bottom)\n",
    "and a total of $p_\\textrm{w}$ columns of padding\n",
    "(roughly half on the left and half on the right),\n",
    "the output shape will be\n",
    "\n",
    "$$(n_\\textrm{h}-k_\\textrm{h}+p_\\textrm{h}+1)\\times(n_\\textrm{w}-k_\\textrm{w}+p_\\textrm{w}+1).$$\n",
    "\n",
    "This means that the height and width of the output\n",
    "will increase by $p_\\textrm{h}$ and $p_\\textrm{w}$, respectively.\n",
    "\n",
    "In many cases, we will want to set $p_\\textrm{h}=k_\\textrm{h}-1$ and $p_\\textrm{w}=k_\\textrm{w}-1$\n",
    "to give the input and output the same height and width.\n",
    "This will make it easier to predict the output shape of each layer\n",
    "when constructing the network.\n",
    "\n",
    "CNNs commonly use convolution kernels\n",
    "with odd height and width values, such as 1, 3, 5, or 7.\n",
    "Choosing odd kernel sizes has the benefit\n",
    "that we can preserve the dimensionality\n",
    "while padding with the same number of rows on top and bottom,\n",
    "and the same number of columns on left and right.\n",
    "\n",
    "Moreover, this practice of using odd kernels\n",
    "and padding to precisely preserve dimensionality\n",
    "offers a clerical benefit.\n",
    "For any two-dimensional tensor `X`,\n",
    "when the kernel's size is odd\n",
    "and the number of padding rows and columns\n",
    "on all sides are the same,\n",
    "thereby producing an output with the same height and width as the input,\n",
    "we know that the output `Y[i, j]` is calculated\n",
    "by cross-correlation of the input and convolution kernel\n",
    "with the window centered on `X[i, j]`.\n",
    "\n",
    "In the following example, we create a two-dimensional convolutional layer\n",
    "with a height and width of 3\n",
    "and apply 1 pixel of padding on all sides.\n",
    "Given an input with a height and width of 8,\n",
    "we find that the height and width of the output is also 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060d592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiayuhuang/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# We define a helper function to calculate convolutions. It initializes the\n",
    "# convolutional layer weights and performs corresponding dimensionality\n",
    "# elevations and reductions on the input and output\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
    "# are added\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba87b82",
   "metadata": {},
   "source": [
    "When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c132c612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a convolution kernel with height 5 and width 3. The padding on either\n",
    "# side of the height and width are 2 and 1, respectively\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c64910",
   "metadata": {},
   "source": [
    "## 5.3.2 Stride\n",
    "\n",
    "In the previous examples, we defaulted to sliding one element at a time.\n",
    "However, sometimes, either for computational efficiency\n",
    "or because we wish to downsample,\n",
    "we move our window more than one element at a time,\n",
    "skipping the intermediate locations.We refer to the number of rows and columns traversed per slide as *stride*.\n",
    " \n",
    "In general, when the stride for the height is $s_\\textrm{h}$\n",
    "and the stride for the width is $s_\\textrm{w}$, the output shape is\n",
    "\n",
    "$$\\lfloor(n_\\textrm{h}-k_\\textrm{h}+p_\\textrm{h}+s_\\textrm{h})/s_\\textrm{h}\\rfloor \\times \\lfloor(n_\\textrm{w}-k_\\textrm{w}+p_\\textrm{w}+s_\\textrm{w})/s_\\textrm{w}\\rfloor.$$\n",
    "\n",
    "If we set $p_\\textrm{h}=k_\\textrm{h}-1$ and $p_\\textrm{w}=k_\\textrm{w}-1$,\n",
    "then the output shape can be simplified to\n",
    "$\\lfloor(n_\\textrm{h}+s_\\textrm{h}-1)/s_\\textrm{h}\\rfloor \\times \\lfloor(n_\\textrm{w}+s_\\textrm{w}-1)/s_\\textrm{w}\\rfloor$.\n",
    "Going a step further, if the input height and width\n",
    "are divisible by the strides on the height and width,\n",
    "then the output shape will be $(n_\\textrm{h}/s_\\textrm{h}) \\times (n_\\textrm{w}/s_\\textrm{w})$.\n",
    "\n",
    "Below, we set the strides on both the height and width to 2,\n",
    "thus halving the input height and width.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9377c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941836b1",
   "metadata": {},
   "source": [
    "Let's look at a slightly more complicated example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5760680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
