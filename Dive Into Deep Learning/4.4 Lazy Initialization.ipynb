{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c3a8ea",
   "metadata": {},
   "source": [
    "# 4.4 Lazy Initialization\n",
    "\n",
    "So far, it might seem that we got away\n",
    "with being sloppy in setting up our networks.\n",
    "Specifically, we did the following unintuitive things,\n",
    "which might not seem like they should work:\n",
    "\n",
    "* We defined the network architectures\n",
    "  without specifying the input dimensionality.\n",
    "* We added layers without specifying\n",
    "  the output dimension of the previous layer.\n",
    "* We even \"initialized\" these parameters\n",
    "  before providing enough information to determine\n",
    "  how many parameters our models should contain.\n",
    "  \n",
    "The trick here is that the framework *defers initialization*,\n",
    "waiting until the first time we pass data through the model,\n",
    "to infer the sizes of each layer on the fly.\n",
    "\n",
    "To begin, let's instantiate an MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d042904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiayuhuang/anaconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8741ade2",
   "metadata": {},
   "source": [
    "At this point, the network cannot possibly know the dimensions of the input layer's weights because the input dimension remains unknown.\n",
    "\n",
    "Consequently the framework has not yet initialized any parameters. We confirm by attempting to access the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1fd83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UninitializedParameter>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d8dc3",
   "metadata": {},
   "source": [
    "Next let's pass data through the network to make the framework finally initialize parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f28aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 20])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "\n",
    "net[0].weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018288c",
   "metadata": {},
   "source": [
    "As soon as we know the input dimensionality,\n",
    "20,\n",
    "the framework can identify the shape of the first layer's weight matrix by plugging in the value of 20.\n",
    "Having recognized the first layer's shape, the framework proceeds\n",
    "to the second layer,\n",
    "and so on through the computational graph\n",
    "until all shapes are known.\n",
    "Note that in this case,\n",
    "only the first layer requires lazy initialization,\n",
    "but the framework initializes sequentially.\n",
    "Once all parameter shapes are known,\n",
    "the framework can finally initialize the parameters.\n",
    "\n",
    "The following method\n",
    "passes in dummy inputs\n",
    "through the network\n",
    "for a dry run\n",
    "to infer all parameter shapes\n",
    "and subsequently initializes the parameters.\n",
    "It will be used later when default random initializations are not desired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff80c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.Module)  #@save\n",
    "def apply_init(self, inputs, init=None):\n",
    "    self.forward(*inputs)\n",
    "    if init is not None:\n",
    "        self.net.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9b040",
   "metadata": {},
   "source": [
    "Lazy initialization can be convenient, allowing the framework to infer parameter shapes automatically, making it easy to modify architectures and eliminating one common source of errors.\n",
    "We can pass data through the model to make the framework finally initialize parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
