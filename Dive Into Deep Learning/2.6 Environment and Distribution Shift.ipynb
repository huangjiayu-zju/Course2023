{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afeed84a",
   "metadata": {},
   "source": [
    "# 2.6 Environment and Distribution Shift\n",
    "\n",
    "\n",
    "## 2.6.1 Types of Distribution Shift\n",
    "In one classic setup, we assume that our training data\n",
    "was sampled from some distribution $p_S(\\mathbf{x},y)$\n",
    "but that our test data will consist\n",
    "of unlabeled examples drawn from\n",
    "some different distribution $p_T(\\mathbf{x},y)$.\n",
    "Already, we must confront a sobering reality.\n",
    "Absent any assumptions on how $p_S$\n",
    "and $p_T$ relate to each other,\n",
    "learning a robust classifier is impossible.\n",
    "\n",
    "Covariate shifts, label shifts, and conceptual shifts are three common scenarios for describing changes in the distribution of data, and they help us to understand under what circumstances a model may be underperforming and to consider how to adapt to these changes.\n",
    "\n",
    "### Covariate Shift\n",
    "we assume that while the distribution of inputs\n",
    "may change over time, the labeling function,\n",
    "i.e., the conditional distribution\n",
    "$P(y \\mid \\mathbf{x})$ does not change.\n",
    "Statisticians call this *covariate shift*\n",
    "because the problem arises due to a\n",
    "shift in the distribution of the covariates (features).\n",
    "\n",
    "协变量转移：输入数据（特征或协变量）的分布在训练集和测试集之间发生了变化，但在给定输入的条件下输出（或标签）的分布保持不变\n",
    "\n",
    "### Label Shift\n",
    "*Label shift* describes the converse problem.\n",
    "Here, we assume that the label marginal $P(y)$\n",
    "can change\n",
    "but the class-conditional distribution\n",
    "$P(\\mathbf{x} \\mid y)$ remains fixed across domains.\n",
    "Label shift is a reasonable assumption to make\n",
    "when we believe that $y$ causes $\\mathbf{x}$.\n",
    "\n",
    "标签转移：标签的整体分布在训练和测试数据之间发生了变化，但在给定特定标签的条件下输入数据的分布保持不变。\n",
    "### Concept Shift\n",
    "*concept shift* arises when the very definitions of labels can change.\n",
    "\n",
    "概念转移：标签或类别定义本身发生变化的情况。它通常涉及到时间或地理位置的变化，导致某些词语或概念的含义发生变化\n",
    "\n",
    "\n",
    "## 2.6.2 Correction of Distribution Shift\n",
    "\n",
    "### Empirical Risk and Risk\n",
    "\n",
    "The model is trained by iterating over features and labels and adjusting its parameters to minimize the loss on the training set.\n",
    "This is termed as minimizing the empirical risk.\n",
    "Ideally, you'd want to minimize the risk over the entire population, but in practice, we only have a sample of this population, so we minimize the empirical risk instead.\n",
    "\n",
    "### Covariate Shift Correction\n",
    "\n",
    "\n",
    "\n",
    "## 2.6.3 A Taxonomy of Learning Problems\n",
    "\n",
    "### Batch Learning\n",
    "\n",
    "Train a model using a fixed dataset and then deploy it to make predictions on new data that comes from the same distribution. The model isn't updated after deployment.\n",
    "\n",
    "### Online Learning\n",
    "Data arrives sequentially. First, you see a new data point, make a prediction based on your current model, then observe the true label and adjust the model accordingly.\n",
    "\n",
    "### Bandits\n",
    "A simplified online learning scenario where instead of a continuous function to optimize, you have a finite set of options (or \"arms\") to choose from. You want to maximize your reward by picking the best options over time.\n",
    "\n",
    "\n",
    "### Control\n",
    "Managing a system where the environment remembers past actions. The system's subsequent states are influenced by prior actions.\n",
    "\n",
    "### Reinforcement Learning\n",
    "Operating in an environment with memory, where every action leads to a certain reward. The aim is to learn a strategy to maximize rewards over time. The environment can be cooperative or adversarial.\n",
    "\n",
    "### Considering the Environment\n",
    "Realizing that strategies that work in static environments might not always work in adaptive ones. The dynamics of how and when the environment changes influence the strategies and algorithms we employ.\n",
    "\n",
    "\n",
    "## 2.6.4 Summary\n",
    "\n",
    "In many cases training and test sets do not come from the same distribution. This is called distribution shift. The risk is the expectation of the loss over the entire population of data drawn from their true distribution. However, this entire population is usually unavailable. Empirical risk is an average loss over the training data to approximate the risk. In practice, we perform empirical risk minimization.\n",
    "\n",
    "Under the corresponding assumptions, covariate and label shift can be detected and corrected for at test time. Failure to account for this bias can become problematic at test time. In some cases, the environment may remember automated actions and respond in surprising ways. We must account for this possibility when building models and continue to monitor live systems, open to the possibility that our models and the environment will become entangled in unanticipated ways.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
