{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ddf91d",
   "metadata": {},
   "source": [
    "# 5.4 Multiple Input and Multiple Output Channels\n",
    "\n",
    "## 5.4.1 Multiple Input Channels\n",
    "\n",
    "\n",
    "When the input data contains multiple channels,\n",
    "we need to construct a convolution kernel\n",
    "with the same number of input channels as the input data,\n",
    "so that it can perform cross-correlation with the input data.\n",
    "Assuming that the number of channels for the input data is $c_\\textrm{i}$,\n",
    "the number of input channels of the convolution kernel also needs to be $c_\\textrm{i}$.\n",
    "\n",
    "When $c_\\textrm{i}>1$, we need a kernel\n",
    "that contains a tensor of shape $k_\\textrm{h}\\times k_\\textrm{w}$ for *every* input channel. Concatenating these $c_\\textrm{i}$ tensors together\n",
    "yields a convolution kernel of shape $c_\\textrm{i}\\times k_\\textrm{h}\\times k_\\textrm{w}$.\n",
    "Since the input and convolution kernel each have $c_\\textrm{i}$ channels,\n",
    "we can perform a cross-correlation operation\n",
    "on the two-dimensional tensor of the input\n",
    "and the two-dimensional tensor of the convolution kernel\n",
    "for each channel, adding the $c_\\textrm{i}$ results together\n",
    "(summing over the channels)\n",
    "to yield a two-dimensional tensor.\n",
    "This is the result of a two-dimensional cross-correlation\n",
    "between a multi-channel input and\n",
    "a multi-input-channel convolution kernel. The following figure provides an example \n",
    "of a two-dimensional cross-correlation with two input channels.\n",
    "The shaded portions are the first output element\n",
    "as well as the input and kernel tensor elements used for the output computation:\n",
    "$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$.\n",
    "\n",
    "![Cross-correlation computation with two input channels.](./img/conv-multi-in.svg)\n",
    "\n",
    "We can implement cross-correlation operations with multiple input channels ourselves. Notice that all we are doing is performing a cross-correlation operation per channel and then adding up the results.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fef0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fd1f7",
   "metadata": {},
   "source": [
    "We can construct the input tensor `X` and the kernel tensor `K`\n",
    "corresponding to the values in the figure\n",
    "to validate the output of the cross-correlation operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51821f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372b8d8",
   "metadata": {},
   "source": [
    "## 5.4.2 Multiple Output Channels\n",
    "\n",
    "Denote by $c_\\textrm{i}$ and $c_\\textrm{o}$ the number\n",
    "of input and output channels, respectively,\n",
    "and by $k_\\textrm{h}$ and $k_\\textrm{w}$ the height and width of the kernel.\n",
    "To get an output with multiple channels,\n",
    "we can create a kernel tensor\n",
    "of shape $c_\\textrm{i}\\times k_\\textrm{h}\\times k_\\textrm{w}$\n",
    "for *every* output channel.\n",
    "We concatenate them on the output channel dimension,\n",
    "so that the shape of the convolution kernel\n",
    "is $c_\\textrm{o}\\times c_\\textrm{i}\\times k_\\textrm{h}\\times k_\\textrm{w}$.\n",
    "In cross-correlation operations,\n",
    "the result on each output channel is calculated\n",
    "from the convolution kernel corresponding to that output channel\n",
    "and takes input from all channels in the input tensor.\n",
    "\n",
    "We implement a cross-correlation function\n",
    "to calculate the output of multiple channels as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a63730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of K, and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273df732",
   "metadata": {},
   "source": [
    "We construct a trivial convolution kernel with three output channels\n",
    "by concatenating the kernel tensor for `K` with `K+1` and `K+2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d378430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9875682",
   "metadata": {},
   "source": [
    "Below, we perform cross-correlation operations\n",
    "on the input tensor `X` with the kernel tensor `K`.\n",
    "Now the output contains three channels.\n",
    "The result of the first channel is consistent\n",
    "with the result of the previous input tensor `X`\n",
    "and the multi-input channel,\n",
    "single-output channel kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f4d76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7aed5",
   "metadata": {},
   "source": [
    "## 5.4.3 $1\\times 1$ Convolutional Layer\n",
    "\n",
    "At first, a $1 \\times 1$ convolution, i.e., $k_\\textrm{h} = k_\\textrm{w} = 1$,\n",
    "does not seem to make much sense.\n",
    "After all, a convolution correlates adjacent pixels.\n",
    "A $1 \\times 1$ convolution obviously does not.\n",
    "Nonetheless, they are popular operations that are sometimes included\n",
    "in the designs of complex deep networks \n",
    "\n",
    "The following figure shows the cross-correlation computation\n",
    "using the $1\\times 1$ convolution kernel\n",
    "with 3 input channels and 2 output channels.\n",
    "Note that the inputs and outputs have the same height and width.\n",
    "Each element in the output is derived\n",
    "from a linear combination of elements *at the same position*\n",
    "in the input image.\n",
    "You could think of the $1\\times 1$ convolutional layer\n",
    "as constituting a fully connected layer applied at every single pixel location\n",
    "to transform the $c_\\textrm{i}$ corresponding input values into $c_\\textrm{o}$ output values.\n",
    "Because this is still a convolutional layer,\n",
    "the weights are tied across pixel location.\n",
    "Thus the $1\\times 1$ convolutional layer requires $c_\\textrm{o}\\times c_\\textrm{i}$ weights\n",
    "(plus the bias). Also note that convolutional layers are typically followed \n",
    "by nonlinearities. This ensures that $1 \\times 1$ convolutions cannot simply be \n",
    "folded into other convolutions.\n",
    "\n",
    "* **Channel Variation**: $1 \\times 1$ convolution can be used to increase or decrease the number of output channels.\n",
    "* **Adding Non-linearity**: Although the $1 \\times 1$ convolution is linear by itself, by adding a non-linear activation function (like ReLU) after it, the model's non-linear properties can be enhanced. This increases the expressive capacity of the model, enabling it to learn more complex functions.\n",
    "* **Computational Efficiency**: In some deep network architectures, the $1 \\times 1$ convolution acts as a method to reduce computation, especially before and after larger convolutions. By reducing the number of channels, they can significantly cut down the number of parameters and computational requirements of the network.\n",
    "* **Feature Interaction**: While $1 \\times 1$ convolution are spatially constrained (since they look at just one pixel at a time), they indeed operate across channels. This implies that they can learn the interactions and relationships between different channels.\n",
    "\n",
    "![The cross-correlation computation uses the $1\\times 1$ convolution kernel with three input channels and two output channels. The input and output have the same height and width.](./img/conv-1x1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce8ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52115a02",
   "metadata": {},
   "source": [
    "When performing $1\\times 1$ convolutions,\n",
    "the above function is equivalent to the previously implemented cross-correlation function `corr2d_multi_in_out`.\n",
    "Let's check this with some sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7f1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61703933",
   "metadata": {},
   "source": [
    "## 5.4.4 Discussion\n",
    "\n",
    "Channels allow us to combine the best of both worlds: MLPs that allow for significant nonlinearities and convolutions that allow for *localized* analysis of features. In particular, channels allow the CNN to reason with multiple features, such as edge and shape detectors at the same time. They also offer a practical trade-off between the drastic parameter reduction arising from translation invariance and locality, and the need for expressive and diverse models in computer vision. \n",
    "\n",
    "Note, though, that this flexibility comes at a price. Given an image of size $(h \\times w)$, the cost for computing a $k \\times k$ convolution is $\\mathcal{O}(h \\cdot w \\cdot k^2)$. For $c_\\textrm{i}$ and $c_\\textrm{o}$ input and output channels respectively this increases to $\\mathcal{O}(h \\cdot w \\cdot k^2 \\cdot c_\\textrm{i} \\cdot c_\\textrm{o})$. For a $256 \\times 256$ pixel image with a $5 \\times 5$ kernel and $128$ input and output channels respectively this amounts to over 53 billion operations (we count multiplications and additions separately). Later on we will encounter effective strategies to cut down on the cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
